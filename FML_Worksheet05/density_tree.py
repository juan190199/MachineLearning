import numpy as np

from base import Tree


def make_density_split_node(node, N, feature_indices):
    """
    Selects dimension and threshold where node is to be split up

    :param node:

    :param N:

    :param feature_indices: array-like of shape (D_try, )
        Contains feature indices to be considered in the present split

    :return: tuple

    """
    n, D = node.data.shape
    m, M = node.box

    # Find best feature j (among 'feature_indices') and best threshold t for the split
    e_min = float("inf")
    j_min, t_min = None, None

    for j in feature_indices:
        # Duplicate feature values have to be removed because candidate thresholds are
        # the midpoints of consecutive feature values, not the feature value itself
        dj = np.sort(np.unique(node.data[:, j]))
        # Compute candidate thresholds
        tj = (dj[1:] + dj[:-1]) / 2

        # Illustration: for loop - hint: vectorized version is possible
        for t in tj:
            # Compute the error
            loo_error = ...

            # choose the best threshold that
            if loo_error < e_min:
                e_min = ...
                j_min = ...
                t_min = ...

    # create children
    left = Node()
    right = Node()

    # initialize 'left' and 'right' with the data subsets and bounding boxes
    # according to the optimal split found above
    left.data = ...  # store data in left node -- for subsequent splits
    left.box = ...  # store bounding box in left node
    right.data = ...
    right.box = ...

    # turn the current 'node' into a split node
    # (store children and split condition)
    node.left = left
    node.right = right
    node.feature = ...
    node.threshold = ...

    # return the children (to be placed on the stack)
    return left, right


class DensityTree(Tree):
    """
    Linear Discriminant Analysis: Classifier with a linear decision boundary,
    generated by fitting class conditional densities to the data using Bayes' rule

    The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix

    The fitted model can also be used to reduce the dimensionality of the input,
    by projecting it to the most discriminative directions.

    Attributes
    -----------
    * prior_:

    * box_:

    * root_:

    """
    def __init__(self):
        super(DensityTree, self).__init__()

    def train(self, data, prior, n_min=20):
        """

        :param data: array-like of shape (n_samples, n_features)
            Design matrix

        :param prior:
            the prior probability of this digit???

        :param n_min: int, default=20
            Termination criterion (Do not split if node contains fewer instances)
        :return:
        """
        self.prior_ = prior
        N, D = data.shape
        D_try = int(np.sqrt(D))  # Number of features to consider for each split decision

        # Find and remember the tree's bounding box,
        # i.e. the lower and upper limits of the training feature set
        m, M = np.min(data, axis=0), np.max(data, axis=0)
        self.box_ = m.copy(), M.copy()

        # Identify invalid features and adjust the bounding box
        # (If m[j] == M[j] for some j, the bounding box has zero volume,
        # causing divide-by-zero errors later on. These
        # features are excluded from splitting and adjust the bounding box limits
        # such that invalid features have no effect on the volume.)
        valid_features = np.where(m != M)[0]
        invalid_features = np.where(m == M)[0]
        M[invalid_features] = m[invalid_features] + 1

        # initialize the root node
        self.root_.data = data
        self.root_.box = m.copy(), M.copy()

        # Build the tree
        stack = [self.root_]
        while len(stack):
            node = stack.pop()
            n = node.data.shape[0]  # Number of instances in present node
            if n >= n_min:
                perm = np.random.permutation(len(valid_features))
                left, right = make_density_split_node(node, N, valid_features[perm][:D_try])
                stack.append(left)
                stack.append(right)
            else:
                # Call 'make_density_leaf_node()' to turn 'node' into a leaf node.
                ...  # your code here

    def predict(self, x):
        """

        :param x:
        :return:
        """
        leaf = self.find_leaf(x)
        # return p(x | y) * p(y) if x is within the tree's bounding box
        # and return 0 otherwise
        return ...  # your code here
