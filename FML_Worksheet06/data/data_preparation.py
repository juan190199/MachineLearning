import numpy as npimport pandas as pdimport osdef data_preparation():    """    Loading and cleaning the data    :return:    """    # Load dataset    filename = os.path.join('data', 'CrowdstormingDataJuly1st.csv')    df = original_df = pd.read_csv(filename, sep=",", header=0)    # print(df.columns, '\n')    # print("Shape of the raw data: ", df.shape, '\n')    mask = pd.notnull(df['photoID'])    # print("Number of missing photo IDs", df.shape[0] - np.sum(mask))    # Drop rows with missing IDs    df = df.loc[mask]    assert np.sum(pd.isnull(df['rater1'])) == 0    assert np.sum(pd.isnull(df['rater2'])) == 0    # Number of unique 'player's and 'playerShort's does not agree.    # Therefore, dataframe key 'playerShort' has to be used as a unique identifier for each player    print("Number of unique playerShorts: ", np.unique(df['playerShort']).shape)    print("Number of unique players: ", np.unique(df['player']).shape, '\n')    # The number of ref countries is consistent    assert np.unique(df['refCountry']).shape[0] == len(df['Alpha_3'].unique())    # Drop irrelevant features    # photoID: holds no relevant information    # meanIAT, nIAT, seIAT, meanEXP, nExp, seEXP: These values stand for racial biases in the referee countries.    # Hence of no interest for the problem problem    # yellowCards: Only interested in the number of red cards    # Alpha_3: Abbreviations for the referee countrys are redundant    irrelevant_feats = ['photoID', 'Alpha_3', 'yellowCards', 'meanIAT', 'nIAT',                        'seIAT', 'meanExp', 'nExp', 'seExp', 'refNum', 'refCountry']    df.drop(irrelevant_feats, axis=1, inplace=True)    # print("Shape of dataset after dropping irrelevant features: ", df.shape)    # Drop all rows with missing values    df.dropna(axis=0, inplace=True)    # print("Shape of dataset after dropping missing values:", df.shape)    # Since only the number of red cards, regardless of the ref, is interesting for the problem,    # all rows corresponding to the same player have to be summed, while keeping entry independent values    # (e.g. club, birthday, etc) constant    gdf = df.groupby(['playerShort'])    variable_features = ['games', 'victories', 'ties', 'defeats', 'goals', 'yellowReds', 'redCards']    static_features = ['playerShort', 'player', 'club', 'leagueCountry', 'birthday',                       'height', 'weight', 'position', 'rater1', 'rater2']    variable_data = gdf[variable_features].sum()    static_data = df[static_features]    static_data = static_data.drop_duplicates()    aggregated_df = variable_data.join(static_data.set_index('playerShort'), on='playerShort')    data = aggregated_df.copy()    del df    # Implementation of new feature and target from the dataset    data['rating'] = (data.loc[:, 'rater1'] + data.loc[:, 'rater2']) / 2    data.drop(['rater1', 'rater2'], axis=1, inplace=True)    return data, aggregated_df